{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cKY4L2LhUCwd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.20.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kns-BC0AgBLm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Coding Related\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(layers.Dense(7 * 7 * 256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding=\"same\", use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding=\"same\", use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding=\"same\",\n",
    "                                     use_bias=False, activation='tanh'))\n",
    "\n",
    "    return model\n",
    "\n",
    "generator = make_generator_model()\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow((generated_image[0, :, :, 0] * 0.5) + 0.5, cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Generator Output Check\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SSbYPvYxgFBC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator output: tf.Tensor([[-0.00016338]], shape=(1, 1), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Coding Related\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding=\"same\",\n",
    "                            input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding=\"same\"))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))   # from_logits=True → no activation\n",
    "\n",
    "    return model\n",
    "\n",
    "discriminator = make_discriminator_model()\n",
    "disc_output = discriminator(generated_image)\n",
    "print(\"Discriminator output:\", disc_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8A3dONHkgIVu"
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    return real_loss + fake_loss\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nJCEyGP7gOH6",
    "outputId": "044868e1-8bf6-429f-f553-67b03634ca08"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    batch_size = tf.shape(images)[0]\n",
    "    noise = tf.random.normal([batch_size, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return gen_loss, disc_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model(test_input, training=False)\n",
    "    predictions = (predictions * 0.5) + 0.5   # [-1,1] → [0,1]\n",
    "\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    os.makedirs(\"generated_images\", exist_ok=True)\n",
    "    filename = f\"generated_images/epoch_{epoch:04d}.png\"\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "    print(f\"Saved: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        start = time.time()\n",
    "        gen_loss_avg = 0.0\n",
    "        disc_loss_avg = 0.0\n",
    "        steps = 0\n",
    "\n",
    "        for image_batch in dataset:\n",
    "            gen_loss, disc_loss = train_step(image_batch)\n",
    "            gen_loss_avg += gen_loss\n",
    "            disc_loss_avg += disc_loss\n",
    "            steps += 1\n",
    "\n",
    "        gen_loss_avg /= steps\n",
    "        disc_loss_avg /= steps\n",
    "\n",
    "        print(f\"Epoch {epoch}/{epochs} | \"\n",
    "              f\"Gen Loss: {gen_loss_avg:.4f} | Disc Loss: {disc_loss_avg:.4f} | \"\n",
    "              f\"Time: {time.time() - start:.2f}s\")\n",
    "\n",
    "        generate_and_save_images(generator, epoch, seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset ready:  60000  images\n",
      "Epoch 1/50 | Gen Loss: 0.8009 | Disc Loss: 1.1498 | Time: 87.27s\n",
      "Saved: generated_images/epoch_0001.png\n",
      "Epoch 2/50 | Gen Loss: 0.8322 | Disc Loss: 1.2734 | Time: 78.97s\n",
      "Saved: generated_images/epoch_0002.png\n",
      "Epoch 3/50 | Gen Loss: 0.8636 | Disc Loss: 1.2899 | Time: 78.33s\n",
      "Saved: generated_images/epoch_0003.png\n",
      "Epoch 4/50 | Gen Loss: 0.8211 | Disc Loss: 1.2976 | Time: 87.07s\n",
      "Saved: generated_images/epoch_0004.png\n",
      "Epoch 5/50 | Gen Loss: 0.8671 | Disc Loss: 1.2490 | Time: 179.72s\n",
      "Saved: generated_images/epoch_0005.png\n",
      "Epoch 6/50 | Gen Loss: 0.9137 | Disc Loss: 1.2489 | Time: 209.21s\n",
      "Saved: generated_images/epoch_0006.png\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining dataset ready: \u001b[39m\u001b[33m\"\u001b[39m, BUFFER_SIZE, \u001b[33m\"\u001b[39m\u001b[33m images\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m     train(train_dataset, epochs)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(batch_size, epochs)\u001b[39m\n\u001b[32m     10\u001b[39m train_dataset = (\n\u001b[32m     11\u001b[39m     tf.data.Dataset\n\u001b[32m     12\u001b[39m     .from_tensor_slices(train_images)\n\u001b[32m     13\u001b[39m     .shuffle(BUFFER_SIZE)\n\u001b[32m     14\u001b[39m     .batch(batch_size, drop_remainder=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     15\u001b[39m )\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining dataset ready: \u001b[39m\u001b[33m\"\u001b[39m, BUFFER_SIZE, \u001b[33m\"\u001b[39m\u001b[33m images\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(dataset, epochs)\u001b[39m\n\u001b[32m      6\u001b[39m steps = \u001b[32m0\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m image_batch \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     gen_loss, disc_loss = \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     gen_loss_avg += gen_loss\n\u001b[32m     11\u001b[39m     disc_loss_avg += disc_loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding Related\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding Related\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding Related\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:869\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    866\u001b[39m   \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    867\u001b[39m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[32m    868\u001b[39m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m869\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    873\u001b[39m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[32m    874\u001b[39m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[32m    875\u001b[39m   \u001b[38;5;28mself\u001b[39m._lock.release()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding Related\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding Related\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding Related\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding Related\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding Related\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding Related\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def main(batch_size=128, epochs=50):\n",
    "    (train_images, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    train_images = train_images.astype(\"float32\")\n",
    "    train_images = (train_images - 127.5) / 127.5\n",
    "    train_images = np.expand_dims(train_images, axis=-1)\n",
    "\n",
    "    BUFFER_SIZE = train_images.shape[0]\n",
    "\n",
    "    train_dataset = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices(train_images)\n",
    "        .shuffle(BUFFER_SIZE)\n",
    "        .batch(batch_size, drop_remainder=True)\n",
    "    )\n",
    "\n",
    "    print(\"Training dataset ready: \", BUFFER_SIZE, \" images\")\n",
    "\n",
    "    train(train_dataset, epochs)\n",
    "\n",
    "main(batch_size=128, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNFpFrjMNIhGtO+7OK9UcGB",
   "gpuType": "L4",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
